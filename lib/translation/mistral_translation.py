import os
import json
import requests
import opencc
import yaml
from typing import List, Dict, Any
from lib.schema import TranslationOutputSchema, TranslationErrorSchema

def load_prompt_from_config(config_path: str) -> str:
    """
    å¾ YAML é…ç½®æª”æ¡ˆè¼‰å…¥ç¿»è­¯æç¤ºè©

    Args:
        config_path: YAML é…ç½®æª”æ¡ˆè·¯å¾‘

    Returns:
        ç¿»è­¯æç¤ºè©æ–‡å­—
    """
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"é…ç½®æª”æ¡ˆä¸å­˜åœ¨ï¼š{config_path}")

    with open(config_path, 'r', encoding='utf-8') as f:
        prompt_content = f.read().strip()

    return prompt_content


def call_vllm(vllm_url: str, model_name: str, text: str) -> str:
    """
    å‘¼å« VLLM æ–¹æ³•å°å–®å¼µåœ–ç‰‡åŸ·è¡Œä»»å‹™

    Args:
        vllm_url: VLLM æœå‹™çš„ URL
        image_url: åœ–ç‰‡çš„ URL æˆ–è·¯å¾‘
        model_name: æ¨¡å‹åç¨±
        text: æç¤ºè©æ–‡å­—ï¼ˆä¾‹å¦‚ï¼š"åŸ·è¡Œ OCR ä»»å‹™ï¼š" æˆ– "ç¿»è­¯æ—¥æ–‡"ï¼‰

    Returns:
        ç”Ÿæˆçš„å›æ‡‰æ–‡å­—
    """

    payload = {
        "model": model_name,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": text
                    }
                ]
            }
        ],
        "temperature": 0.7,
        "repetition_penalty": 1.1,
        "stop": ["<end_of_turn>"],
    }

    try:
        response = requests.post(
            vllm_url,
            json=payload,
            timeout=60
        )
        response.raise_for_status()
        result = response.json()
        return result['choices'][0]['message']['content']
    except requests.exceptions.Timeout:
        print(f"è«‹æ±‚è¶…æ™‚ï¼Œè¿”å›ç©ºå­—ä¸²")
        return ""
    except requests.exceptions.HTTPError as e:
        print(f"HTTP éŒ¯èª¤ï¼š{e}")
        print(f"è«‹æ±‚ URLï¼š{vllm_url}")
        print(f"å›æ‡‰å…§å®¹ï¼š{response.text}")
        return ""
    except Exception as e:
        print(f"æœªé æœŸçš„éŒ¯èª¤ï¼š{e}")
        return ""

def translate_text_with_vllm(
    text: str,
    vllm_url: str = "http://192.168.1.76:3132/v1/chat/completions",
    model_name: str = "mistralai3",
    translate_prompt: str = "å°‡ä»¥ä¸‹æ—¥æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š"
) -> str:
    """
    ä½¿ç”¨ VLLM ç¿»è­¯æ–‡å­—

    Args:
        text: è¦ç¿»è­¯çš„æ–‡å­—
        vllm_url: VLLM æœå‹™ URL
        model_name: æ¨¡å‹åç¨±
        translate_prompt: ç¿»è­¯æç¤ºè©

    Returns:
        ç¿»è­¯å¾Œçš„æ–‡å­—
    """
    # åˆå§‹åŒ– OpenCC è½‰æ›å™¨ï¼ˆç°¡é«”è½‰ç¹é«”ï¼‰
    # cc = opencc.OpenCC('s2tw')

    # å‘¼å« VLLM é€²è¡Œç¿»è­¯
    full_prompt = f"{translate_prompt}\n\n{text}"
    translated_text = call_vllm(vllm_url, model_name, full_prompt)

    # ä½¿ç”¨ OpenCC ç¢ºä¿ç¹é«”ä¸­æ–‡æ­£ç¢º
    # translated_text = cc.convert(translated_text)

    return translated_text


def translate_ocr_json(
    ocr_json_path: str,
    vllm_url: str = "http://192.168.1.76:3132/v1/chat/completions",
    model_name: str = "mistralai3",
    output_path: str = None,
    translate_prompt: str = "å°‡ä»¥ä¸‹æ—¥æ–‡ç¿»è­¯æˆç¹é«”ä¸­æ–‡ï¼š"
) -> None:
    """
    å¾ OCR JSON æª”æ¡ˆè¼‰å…¥çµæœä¸¦é€²è¡Œç¿»è­¯

    Args:
        ocr_json_path: OCR çµæœçš„ JSON æª”æ¡ˆè·¯å¾‘
        vllm_url: VLLM æœå‹™ URL
        model_name: æ¨¡å‹åç¨±
        output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆè‹¥æœªæŒ‡å®šå‰‡è‡ªå‹•ç”Ÿæˆï¼‰
        translate_prompt: ç¿»è­¯æç¤ºè©
    """
    # è¼‰å…¥ OCR çµæœ
    print(f"ğŸ“ è¼‰å…¥ OCR çµæœï¼š{ocr_json_path}")
    with open(ocr_json_path, 'r', encoding='utf-8') as f:
        ocr_results = json.load(f)

    print(f"âœ… æ‰¾åˆ° {len(ocr_results)} ç­† OCR çµæœ\n")

    # è™•ç†æ¯ç­† OCR çµæœ
    results: List[Dict[str, Any]] = []
    for idx, ocr_item in enumerate(ocr_results, 1):
        # è·³ééŒ¯èª¤é …ç›®
        if 'error' in ocr_item:
            print(f"â­ï¸  è·³éç¬¬ {idx} ç­†ï¼ˆOCR å¤±æ•—ï¼‰ï¼š{ocr_item.get('source', 'unknown')}")
            results.append(ocr_item)
            continue

        source = ocr_item.get('source', ocr_item.get('image_path', 'unknown'))
        ocr_text = ocr_item.get('text', '')

        print(f"ğŸ”„ è™•ç†é€²åº¦ï¼š{idx}/{len(ocr_results)} - {os.path.basename(source)}")
        print(f"   åŸæ–‡é•·åº¦ï¼š{len(ocr_text)} å­—å…ƒ")

        try:
            # ç¿»è­¯ OCR æ–‡å­—
            print(f"   ğŸŒ åŸ·è¡Œç¿»è­¯...")
            translated_text = translate_text_with_vllm(
                text=ocr_text,
                vllm_url=vllm_url,
                model_name=model_name,
                translate_prompt=translate_prompt
            )
            print(f"   âœ“ ç¿»è­¯å®Œæˆï¼Œè­¯æ–‡é•·åº¦ï¼š{len(translated_text)} å­—å…ƒ")

            # ç¿»è­¯æ¯å€‹é‚Šç•Œæ¡†ä¸­çš„æ–‡å­—
            translated_bboxes = []
            if 'bounding_boxes' in ocr_item and ocr_item['bounding_boxes']:
                print(f"   ğŸ”„ ç¿»è­¯ {len(ocr_item['bounding_boxes'])} å€‹é‚Šç•Œæ¡†...")
                for bbox_idx, bbox in enumerate(ocr_item['bounding_boxes'], 1):
                    bbox_text = bbox.get('text', '')
                    if bbox_text:
                        print(f"      ç¿»è­¯é‚Šç•Œæ¡† {bbox_idx}/{len(ocr_item['bounding_boxes'])}: {bbox_text}")
                        bbox_translated = translate_text_with_vllm(
                            text=bbox_text,
                            vllm_url=vllm_url,
                            model_name=model_name,
                            translate_prompt=translate_prompt
                        )
                        print(f"      çµæœ: {bbox_translated}\\n")
                    else:
                        bbox_translated = ''

                    translated_bboxes.append({
                        'box': bbox.get('box', []),
                        'text': bbox_text,
                        'score': bbox.get('score'),
                        'translated_text': bbox_translated
                    })

            result: TranslationOutputSchema = {
                "source": source,
                "text": ocr_text,
                "translated_text": translated_text,
                "image_path": ocr_item.get('image_path', source),
                "bounding_boxes": translated_bboxes
            }
            results.append(result)

        except Exception as e:
            print(f"   âœ— ç¿»è­¯å¤±æ•—ï¼š{e}")
            error_result: TranslationErrorSchema = {
                "source": source,
                "error": str(e)
            }
            results.append(error_result)  # type: ignore

    # æ±ºå®šè¼¸å‡ºè·¯å¾‘
    if output_path is None:
        # è‡ªå‹•ç”Ÿæˆè¼¸å‡ºè·¯å¾‘ï¼ˆèˆ‡è¼¸å…¥æª”æ¡ˆåŒç›®éŒ„ï¼‰
        input_dir = os.path.dirname(ocr_json_path)
        output_path = os.path.join(input_dir, "mistral_translated.json")

    # å„²å­˜çµæœ
    output_dir = os.path.dirname(output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š è™•ç†å®Œæˆï¼")
    print(f"{'='*60}")

    success_count = sum(1 for r in results if 'error' not in r)
    failed_count = len(results) - success_count

    print(f"âœ… æˆåŠŸï¼š{success_count} ç­†")
    print(f"âŒ å¤±æ•—ï¼š{failed_count} ç­†")
    print(f"ğŸ’¾ çµæœå·²å„²å­˜è‡³ï¼š{output_path}")


def main():
    """ä¸»ç¨‹å¼"""
    import argparse

    parser = argparse.ArgumentParser(description='ä½¿ç”¨ VLLM (Mistral) æ‰¹æ¬¡ç¿»è­¯')
    parser.add_argument('--data-dir', type=str,
                        help='åœ–ç‰‡è³‡æ–™ç›®éŒ„è·¯å¾‘æˆ– OCR JSON æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--vllm-url', type=str,
                        default='http://192.168.1.76:3132/v1/chat/completions',
                        help='VLLM æœå‹™ URLï¼ˆé è¨­ï¼šhttp://192.168.1.76:3132/v1/chat/completionsï¼‰')
    parser.add_argument('--model-name', type=str,
                        default='mistralai3',
                        help='æ¨¡å‹åç¨±ï¼ˆé è¨­ï¼šmistralai3ï¼‰')
    parser.add_argument('--output-dir', type=str,
                        help='è¼¸å‡ºç›®éŒ„è·¯å¾‘ï¼ˆè‹¥å¾ JSON è¼‰å…¥å‰‡ç‚ºè¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼‰')
    parser.add_argument('--prompt-config', type=str,
                        default='configs/translation_prompt/default.yml',
                        help='ç¿»è­¯æç¤ºè©é…ç½®æª”æ¡ˆè·¯å¾‘ï¼ˆé è¨­ï¼šconfigs/translation_prompt/default.ymlï¼‰')

    args = parser.parse_args()

    if not args.data_dir:
        parser.error('éœ€è¦æä¾› --data-dir åƒæ•¸')

    # è¼‰å…¥ç¿»è­¯æç¤ºè©
    translate_prompt = load_prompt_from_config(args.prompt_config)
    print(f"ğŸ“ è¼‰å…¥ç¿»è­¯æç¤ºè©é…ç½®ï¼š{args.prompt_config}")
    print(f"æç¤ºè©é•·åº¦ï¼š{len(translate_prompt)} å­—å…ƒ\n")

    translate_ocr_json(
        ocr_json_path=args.data_dir,
        vllm_url=args.vllm_url,
        model_name=args.model_name,
        output_path=args.output_dir,
        translate_prompt=translate_prompt
    )


if __name__ == "__main__":
    main()