import os
os.environ["FLAGS_allocator_strategy"] = "naive_best_fit"
# å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
os.environ['FLAGS_eager_delete_tensor_gb'] = '0.0'
os.environ['FLAGS_fast_eager_deletion_mode'] = '1'

from paddleocr import PaddleOCR
import base64
from io import BytesIO
from PIL import Image
import argparse
import sys

import json
import glob
from datetime import datetime
import paddle
import gc
import shutil


class OCR:
    def __init__(self, text_det_model_dir, text_recognition_model_dir=None, max_output_dirs: int = 5, output_dir: str = None):

        self.ocr = PaddleOCR(
            text_recognition_model_dir=text_recognition_model_dir,
            text_detection_model_dir=text_det_model_dir,
            use_doc_orientation_classify=False, # é€šè¿‡ use_doc_orientation_classify å‚æ•°æŒ‡å®šä¸ä½¿ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»æ¨¡å‹
            use_doc_unwarping=False, # é€šè¿‡ use_doc_unwarping å‚æ•°æŒ‡å®šä¸ä½¿ç”¨æ–‡æœ¬å›¾åƒçŸ«æ­£æ¨¡å‹
            use_textline_orientation=False, # é€šè¿‡ use_textline_orientation å‚æ•°æŒ‡å®šä¸ä½¿ç”¨æ–‡æœ¬è¡Œæ–¹å‘åˆ†ç±»æ¨¡å‹
            lang="japan",
        )
        # è¨­ç½®è‡¨æ™‚ç›®éŒ„
        if output_dir is None:
            output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "output_dir")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.tmp_dir = os.path.join(output_dir, f"layout/{timestamp}")
        os.makedirs(self.tmp_dir, exist_ok=True)

        # è¨­ç½®æœ€å¤§ä¿ç•™çš„è¼¸å‡ºç›®éŒ„æ•¸é‡
        self.max_output_dirs = max_output_dirs

        print(f"âœ… OCR æ¨¡å‹å·²è¼‰å…¥ (PID: {os.getpid()})")
        print(f"   GPU è¨˜æ†¶é«”é™åˆ¶: 40%")

    def _process_image_input(self, image_input):
        """
        è™•ç†ä¸åŒæ ¼å¼çš„åœ–ç‰‡è¼¸å…¥ï¼Œè½‰æ›ç‚ºæª”æ¡ˆè·¯å¾‘

        Args:
            image_input: åœ–ç‰‡è·¯å¾‘ æˆ– PIL Image æˆ– base64 å­—ä¸²

        Returns:
            str: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
        """
        img_ext = ".jpg"  # é è¨­
        if isinstance(image_input, str):
            if image_input.startswith('data:image') or image_input.startswith('/9j'):
                # base64 è¼¸å…¥
                image_data = base64.b64decode(image_input.split(',')[-1])
                image = Image.open(BytesIO(image_data))
                img_format = image.format.lower() if image.format else "jpg"
                img_ext = f".{img_format}"
                img_path = os.path.join(self.tmp_dir, f"temp_ocr{img_ext}")
                image.save(img_path)
            else:
                # æª”æ¡ˆè·¯å¾‘
                img_path = image_input
                img_ext = os.path.splitext(img_path)[1] or ".jpg"
        else:
            # PIL Image
            img_format = image_input.format.lower() if image_input.format else "jpg"
            img_ext = f".{img_format}"
            img_path = os.path.join(self.tmp_dir, f"temp_ocr{img_ext}")
            image_input.save(img_path)

        return img_path

    def _cleanup_old_outputs(self):
        """æ¸…ç†èˆŠçš„è¼¸å‡ºç›®éŒ„ï¼Œåªä¿ç•™æœ€æ–°çš„ N å€‹"""
        output_dirs = sorted(
            [d for d in glob.glob(os.path.join(self.tmp_dir, "ocr_output_*")) if os.path.isdir(d)],
            key=os.path.getmtime
        )

        # åˆªé™¤è¶…éé™åˆ¶çš„èˆŠç›®éŒ„
        if len(output_dirs) > self.max_output_dirs:
            for old_dir in output_dirs[:-self.max_output_dirs]:
                try:
                    shutil.rmtree(old_dir)
                    print(f"ğŸ—‘ï¸  å·²æ¸…ç†èˆŠè¼¸å‡ºç›®éŒ„ï¼š{old_dir}")
                except Exception as e:
                    print(f"âš ï¸  æ¸…ç†ç›®éŒ„å¤±æ•—ï¼š{old_dir}, éŒ¯èª¤ï¼š{e}")

    def _clear_gpu_memory(self):
        """æ¸…ç† GPU è¨˜æ†¶é«”"""
        try:
            # æ¸…ç©º PaddlePaddle çš„ç·©å­˜
            #torch.cuda.empty_cache()
            #paddle.inference.Predictor.try_shrink_memory()
            # å¼·åˆ¶ Python åƒåœ¾å›æ”¶
            gc.collect()
        except Exception as e:
            print(f"âš ï¸  æ¸…ç† GPU è¨˜æ†¶é«”æ™‚å‡ºéŒ¯ï¼š{e}")

    def load_directory(self, directory_path, recursive=True):
        """
        è¼‰å…¥ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ

        Args:
            directory_path: åœ–ç‰‡ç›®éŒ„è·¯å¾‘
            recursive: æ˜¯å¦éè¿´æœå°‹å­ç›®éŒ„ï¼ˆé è¨­ç‚º Trueï¼‰

        Returns:
            list[str]: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        if not os.path.exists(directory_path):
            raise FileNotFoundError(f"ç›®éŒ„ä¸å­˜åœ¨ï¼š{directory_path}")

        if not os.path.isdir(directory_path):
            raise NotADirectoryError(f"è·¯å¾‘ä¸æ˜¯ç›®éŒ„ï¼š{directory_path}")

        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

        image_paths = []

        if recursive:
            # éè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„
            for root, dirs, files in os.walk(directory_path):
                for file in sorted(files):
                    if os.path.splitext(file.lower())[1] in image_extensions:
                        image_paths.append(os.path.join(root, file))
        else:
            # åªæœå°‹ç•¶å‰ç›®éŒ„
            for file in sorted(os.listdir(directory_path)):
                file_path = os.path.join(directory_path, file)
                if os.path.isfile(file_path) and os.path.splitext(file.lower())[1] in image_extensions:
                    image_paths.append(file_path)

        return image_paths

    def predict_batch(self, image_inputs, show_progress=True):
        """
        æ‰¹æ¬¡åŸ·è¡Œ OCR è¾¨è­˜

        Args:
            image_inputs: åœ–ç‰‡è·¯å¾‘åˆ—è¡¨ æˆ– PIL Image åˆ—è¡¨
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦

        Returns:
            list[dict]: æ¯å¼µåœ–ç‰‡çš„è¾¨è­˜çµæœåˆ—è¡¨
        """
        results = []
        total = len(image_inputs)

        for idx, image_input in enumerate(image_inputs, 1):
            if show_progress:
                print(f"ğŸ”„ è™•ç†é€²åº¦ï¼š{idx}/{total} - {os.path.basename(image_input) if isinstance(image_input, str) else f'image_{idx}'}")

            try:
                result = self.predict(image_input)
                result['source'] = image_input if isinstance(image_input, str) else f'image_{idx}'
                results.append(result)
            except Exception as e:
                print(f"âš ï¸  è™•ç†å¤±æ•—ï¼š{image_input if isinstance(image_input, str) else f'image_{idx}'}, éŒ¯èª¤ï¼š{e}")
                results.append({
                    'source': image_input if isinstance(image_input, str) else f'image_{idx}',
                    'error': str(e)
                })

        return results

    def predict(self, image_input):
        """
        åŸ·è¡Œ OCR è¾¨è­˜

        Args:
            image_input: åœ–ç‰‡è·¯å¾‘ æˆ– PIL Image æˆ– base64 å­—ä¸²
        Returns:
            dict: {
                "text": str,                    # æ‰€æœ‰è¾¨è­˜å‡ºçš„æ–‡å­—ï¼ˆæ›è¡Œåˆ†éš”ï¼‰
                "image_path": str,              # æ¨™è¨»åœ–ç‰‡çš„è·¯å¾‘
                "bounding_boxes": list[dict]    # æ¯å€‹æ–‡å­—å€åŸŸçš„åº§æ¨™ã€æ–‡å­—å’Œä¿¡å¿ƒåˆ†æ•¸
                                                # æ ¼å¼: [{"box": [[x1,y1], [x2,y2], [x3,y3], [x4,y4]],
                                                #         "text": str, "score": float}, ...]
            }
        """
        try:
            # è™•ç†è¼¸å…¥æ ¼å¼ä¸¦å–å¾—åœ–ç‰‡è·¯å¾‘
            img_path = self._process_image_input(image_input)

            # OCR è¾¨è­˜
            result = self.ocr.predict(input=img_path)

            # å„²å­˜çµæœï¼ˆåŠ å…¥ timestampï¼‰
            ocr_output_dir = self.tmp_dir
            os.makedirs(ocr_output_dir, exist_ok=True)

            for res in result:
                res.print()
                res.save_to_json(save_path=ocr_output_dir)
                res.save_to_img(save_path=ocr_output_dir)

            # æå–æ–‡å­—å…§å®¹
            json_files = glob.glob(os.path.join(ocr_output_dir, "*.json"))
            if not json_files:
                raise FileNotFoundError(f"No JSON files found in {ocr_output_dir}")

            with open(json_files[0], 'r', encoding='utf-8') as f:
                json_result = json.load(f)

            
            # æå–åœ–ç‰‡é€£çµ
            result_image_path = sorted([f for f in os.listdir(ocr_output_dir) if f.endswith(tuple(['.jpg', '.jpeg', '.png']))])[0]

            # æå– bounding boxes
            bounding_boxes = []
            if "dt_polys" in json_result:
                for i, box in enumerate(json_result["dt_polys"]):
                    bbox_info = {
                        "box": box,
                        "text": json_result["rec_texts"][i] if i < len(json_result["rec_texts"]) else "",
                        "score": json_result["rec_scores"][i] if "rec_scores" in json_result and i < len(json_result["rec_scores"]) else None
                    }
                    bounding_boxes.append(bbox_info)

            response = {
                "text": "\n".join(json_result["rec_texts"]),
                "image_path": result_image_path,
                "bounding_boxes": bounding_boxes
            }

            return response

        finally:
            # æ¯æ¬¡æ¨ç†å¾Œæ¸…ç† GPU è¨˜æ†¶é«”
            self._clear_gpu_memory()
            # æ¸…ç†èˆŠçš„è¼¸å‡ºç›®éŒ„
            self._cleanup_old_outputs()


def main():
    parser = argparse.ArgumentParser(description='PaddleOCR-VL åœ–ç‰‡æ–‡å­—è¾¨è­˜')
    parser.add_argument('--image', type=str, help='å–®å¼µåœ–ç‰‡è·¯å¾‘')
    parser.add_argument('--input-dir', type=str, help='åœ–ç‰‡ç›®éŒ„è·¯å¾‘ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰')
    parser.add_argument('--no-recursive', action='store_true', help='ä¸éè¿´æœå°‹å­ç›®éŒ„ï¼ˆåƒ…ç”¨æ–¼ --input-dirï¼‰')
    parser.add_argument('--model-dir', type=str,
                        default='/tmp2/share_data/models--PaddlePaddle--PaddleOCR-VL/',
                        help='æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--text-det-model-dir', type=str,
                        default=None,
                        help='æ–‡å­—åµæ¸¬æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--text-rec-model-dir', type=str,
                        default=None,
                        help='æ–‡å­—è¾¨è­˜æ¨¡å‹è·¯å¾‘ (é è¨­: PaddleOCR/output/inference/PP-OCRv5_comic_rec_infer_epoch200)')
    parser.add_argument('--output', type=str, help='è¼¸å‡ºæ–‡å­—æª”æ¡ˆè·¯å¾‘ï¼ˆå–®å¼µåœ–ç‰‡ï¼‰æˆ–åˆä½µæ–‡å­—æª”æ¡ˆè·¯å¾‘ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰')
    parser.add_argument('--output-dir', type=str, help='è¼¸å‡ºç›®éŒ„è·¯å¾‘ï¼ˆæ‰¹æ¬¡è™•ç†æ™‚æ¯å¼µåœ–ç‰‡åˆ†åˆ¥å„²å­˜ï¼‰')
    parser.add_argument('--save-image', type=str, help='å„²å­˜æ¨™è¨»åœ–ç‰‡è·¯å¾‘ï¼ˆé¸å¡«ï¼‰')

    args = parser.parse_args()

    # æª¢æŸ¥å¿…é ˆæä¾› --image æˆ– --input-dir å…¶ä¸­ä¹‹ä¸€
    if not args.image and not args.input_dir:
        print(f"âŒ éŒ¯èª¤ï¼šè«‹æä¾› --image æˆ– --input-dir åƒæ•¸", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    if args.image and args.input_dir:
        print(f"âŒ éŒ¯èª¤ï¼š--image å’Œ --input-dir ä¸èƒ½åŒæ™‚ä½¿ç”¨", file=sys.stderr)
        sys.exit(1)

    print(f"ğŸ”§ è¼‰å…¥ OCR æ¨¡å‹...")
    ocr = OCR(
        text_det_model_dir=args.text_det_model_dir,
        text_recognition_model_dir=args.text_rec_model_dir,
        output_dir=args.output_dir
    )

    # å–®å¼µåœ–ç‰‡è™•ç†
    if args.image:
        if not os.path.exists(args.image):
            print(f"âŒ éŒ¯èª¤ï¼šåœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨ - {args.image}", file=sys.stderr)
            sys.exit(1)

        print(f"ğŸ–¼ï¸  è™•ç†åœ–ç‰‡ï¼š{args.image}")
        result = ocr.predict(args.image)

        # è¼¸å‡ºè¾¨è­˜æ–‡å­—
        print("\nğŸ“ å®Œæ•´ JSON çµæœï¼š")
        print("=" * 60)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        print("=" * 60)

        # å„²å­˜è¼¸å‡ºï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(result['text'])
            print(f"\nğŸ’¾ æ–‡å­—å·²å„²å­˜è‡³ï¼š{args.output}")


    # ç›®éŒ„æ‰¹æ¬¡è™•ç†
    elif args.input_dir:
        if not os.path.exists(args.input_dir):
            print(f"âŒ éŒ¯èª¤ï¼šç›®éŒ„ä¸å­˜åœ¨ - {args.input_dir}", file=sys.stderr)
            sys.exit(1)

        print(f"ğŸ“ è¼‰å…¥ç›®éŒ„ï¼š{args.input_dir}")
        recursive = not args.no_recursive
        if not recursive:
            print(f"   æ¨¡å¼ï¼šåƒ…æœå°‹ç•¶å‰ç›®éŒ„ï¼ˆä¸éè¿´ï¼‰")
        else:
            print(f"   æ¨¡å¼ï¼šéè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„")
        image_paths = ocr.load_directory(args.input_dir, recursive=recursive)

        if not image_paths:
            print(f"âš ï¸  è­¦å‘Šï¼šç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡æª”æ¡ˆ", file=sys.stderr)
            sys.exit(0)

        print(f"âœ… æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡\n")

        # æ‰¹æ¬¡è™•ç†
        results = ocr.predict_batch(image_paths)

        # è¼¸å‡ºçµæœæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹æ¬¡è™•ç†çµæœæ‘˜è¦ï¼š")
        print("=" * 60)

        success_count = sum(1 for r in results if 'error' not in r)
        error_count = len(results) - success_count

        print(f"âœ… æˆåŠŸï¼š{success_count} å¼µ")
        print(f"âŒ å¤±æ•—ï¼š{error_count} å¼µ")

        # å„²å­˜çµæœç‚º JSON æª”
        if args.output_dir:
            os.makedirs(args.output_dir, exist_ok=True)
            results_json_path = os.path.join(args.output_dir, "ocr.json")
            with open(results_json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ æ‰¹æ¬¡çµæœå·²å„²å­˜è‡³ï¼š{results_json_path}")


if __name__ == "__main__":
    main()
