import os
os.environ["FLAGS_allocator_strategy"] = "naive_best_fit"
# å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
os.environ['FLAGS_eager_delete_tensor_gb'] = '0.0'
os.environ['FLAGS_fast_eager_deletion_mode'] = '1'


from paddleocr import PaddleOCR
import base64
from io import BytesIO
from PIL import Image
import argparse
import sys

import json
import glob
from datetime import datetime
import paddle
import gc
import shutil
import numpy as np
import cv2

from lib.ocr.paddleocr_vl_manga import PaddleOCRVLMANGA

class OCR:
    def __init__(self, text_det_model_dir, text_recognition_model_dir=None, max_output_dirs: int = 5, output_dir: str = None):

        self.layout = PaddleOCR(
            text_recognition_model_dir=None,
            text_detection_model_dir="PaddleOCR/output/inference/PP-OCRv5_comic_det_infer/",
            use_doc_orientation_classify=False, # é€šè¿‡ use_doc_orientation_classify å‚æ•°æŒ‡å®šä¸ä½¿ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»æ¨¡å‹
            use_doc_unwarping=False, # é€šè¿‡ use_doc_unwarping å‚æ•°æŒ‡å®šä¸ä½¿ç”¨æ–‡æœ¬å›¾åƒçŸ«æ­£æ¨¡å‹
            use_textline_orientation=False, # é€šè¿‡ use_textline_orientation å‚æ•°æŒ‡å®šä¸ä½¿ç”¨æ–‡æœ¬è¡Œæ–¹å‘åˆ†ç±»æ¨¡å‹
        )

        self.ocr = PaddleOCRVLMANGA(
            model_path="/tmp2/share_data/PaddleOCR-VL-For-Manga",
            processor_path="/tmp2/share_data/PaddleOCR-VL-For-Manga",
            task="ocr",
            device="cuda" if paddle.is_compiled_with_cuda() else "cpu",
            max_new_tokens=256,
        )
        
        # è¨­ç½®è‡¨æ™‚ç›®éŒ„
        if output_dir is None:
            output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "output_dir")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.tmp_dir = os.path.join(output_dir, f"layout/{timestamp}")
        os.makedirs(self.tmp_dir, exist_ok=True)

        # è¨­ç½®æœ€å¤§ä¿ç•™çš„è¼¸å‡ºç›®éŒ„æ•¸é‡
        self.max_output_dirs = max_output_dirs

        print(f"âœ… OCR æ¨¡å‹å·²è¼‰å…¥ (PID: {os.getpid()})")

    def _process_image_input(self, image_input):
        """
        è™•ç†ä¸åŒæ ¼å¼çš„åœ–ç‰‡è¼¸å…¥ï¼Œè½‰æ›ç‚ºæª”æ¡ˆè·¯å¾‘

        Args:
            image_input: åœ–ç‰‡è·¯å¾‘ æˆ– PIL Image æˆ– base64 å­—ä¸²

        Returns:
            str: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘
        """
        img_ext = ".jpg"  # é è¨­
        if isinstance(image_input, str):
            if image_input.startswith('data:image') or image_input.startswith('/9j'):
                # base64 è¼¸å…¥
                image_data = base64.b64decode(image_input.split(',')[-1])
                image = Image.open(BytesIO(image_data))
                img_format = image.format.lower() if image.format else "jpg"
                img_ext = f".{img_format}"
                img_path = os.path.join(self.tmp_dir, f"temp_ocr{img_ext}")
                image.save(img_path)
            else:
                # æª”æ¡ˆè·¯å¾‘
                img_path = image_input
                img_ext = os.path.splitext(img_path)[1] or ".jpg"
        else:
            # PIL Image
            img_format = image_input.format.lower() if image_input.format else "jpg"
            img_ext = f".{img_format}"
            img_path = os.path.join(self.tmp_dir, f"temp_ocr{img_ext}")
            image_input.save(img_path)

        return img_path

    def _cleanup_old_outputs(self):
        """æ¸…ç†èˆŠçš„è¼¸å‡ºç›®éŒ„ï¼Œåªä¿ç•™æœ€æ–°çš„ N å€‹"""
        output_dirs = sorted(
            [d for d in glob.glob(os.path.join(self.tmp_dir, "ocr_output_*")) if os.path.isdir(d)],
            key=os.path.getmtime
        )

        # åˆªé™¤è¶…éé™åˆ¶çš„èˆŠç›®éŒ„
        if len(output_dirs) > self.max_output_dirs:
            for old_dir in output_dirs[:-self.max_output_dirs]:
                try:
                    shutil.rmtree(old_dir)
                    print(f"ğŸ—‘ï¸  å·²æ¸…ç†èˆŠè¼¸å‡ºç›®éŒ„ï¼š{old_dir}")
                except Exception as e:
                    print(f"âš ï¸  æ¸…ç†ç›®éŒ„å¤±æ•—ï¼š{old_dir}, éŒ¯èª¤ï¼š{e}")

    def _clear_gpu_memory(self):
        """æ¸…ç† GPU è¨˜æ†¶é«”"""
        try:
            # æ¸…ç©º PaddlePaddle çš„ç·©å­˜
            #torch.cuda.empty_cache()
            #paddle.inference.Predictor.try_shrink_memory()
            # å¼·åˆ¶ Python åƒåœ¾å›æ”¶
            gc.collect()
        except Exception as e:
            print(f"âš ï¸  æ¸…ç† GPU è¨˜æ†¶é«”æ™‚å‡ºéŒ¯ï¼š{e}")

    def load_directory(self, directory_path, recursive=True):
        """
        è¼‰å…¥ç›®éŒ„ä¸­çš„æ‰€æœ‰åœ–ç‰‡æª”æ¡ˆ

        Args:
            directory_path: åœ–ç‰‡ç›®éŒ„è·¯å¾‘
            recursive: æ˜¯å¦éè¿´æœå°‹å­ç›®éŒ„ï¼ˆé è¨­ç‚º Trueï¼‰

        Returns:
            list[str]: åœ–ç‰‡æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        if not os.path.exists(directory_path):
            raise FileNotFoundError(f"ç›®éŒ„ä¸å­˜åœ¨ï¼š{directory_path}")

        if not os.path.isdir(directory_path):
            raise NotADirectoryError(f"è·¯å¾‘ä¸æ˜¯ç›®éŒ„ï¼š{directory_path}")

        # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

        image_paths = []

        if recursive:
            # éè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„
            for root, dirs, files in os.walk(directory_path):
                for file in sorted(files):
                    if os.path.splitext(file.lower())[1] in image_extensions:
                        image_paths.append(os.path.join(root, file))
        else:
            # åªæœå°‹ç•¶å‰ç›®éŒ„
            for file in sorted(os.listdir(directory_path)):
                file_path = os.path.join(directory_path, file)
                if os.path.isfile(file_path) and os.path.splitext(file.lower())[1] in image_extensions:
                    image_paths.append(file_path)

        return image_paths

    def predict_batch(self, image_inputs, show_progress=True):
        """
        æ‰¹æ¬¡åŸ·è¡Œ OCR è¾¨è­˜

        Args:
            image_inputs: åœ–ç‰‡è·¯å¾‘åˆ—è¡¨ æˆ– PIL Image åˆ—è¡¨
            show_progress: æ˜¯å¦é¡¯ç¤ºé€²åº¦

        Returns:
            list[dict]: æ¯å¼µåœ–ç‰‡çš„è¾¨è­˜çµæœåˆ—è¡¨
        """
        results = []
        total = len(image_inputs)

        for idx, image_input in enumerate(image_inputs, 1):
            if show_progress:
                print(f"ğŸ”„ è™•ç†é€²åº¦ï¼š{idx}/{total} - {os.path.basename(image_input) if isinstance(image_input, str) else f'image_{idx}'}")

            try:
                result = self.predict(image_input)
                result['source'] = image_input if isinstance(image_input, str) else f'image_{idx}'
                results.append(result)
            except Exception as e:
                print(f"âš ï¸  è™•ç†å¤±æ•—ï¼š{image_input if isinstance(image_input, str) else f'image_{idx}'}, éŒ¯èª¤ï¼š{e}")
                results.append({
                    'source': image_input if isinstance(image_input, str) else f'image_{idx}',
                    'error': str(e)
                })

        return results

    def predict(self, image_input):
        """
        åŸ·è¡Œ OCR è¾¨è­˜ï¼ˆæ–°æ¶æ§‹ï¼‰

        æµç¨‹ï¼šimg -> self.layout -> bbox -> crop -> self.ocr -> bbox + ocr

        Args:
            image_input: åœ–ç‰‡è·¯å¾‘ æˆ– PIL Image æˆ– base64 å­—ä¸²
        Returns:
            dict: {
                "text": str,                    # æ‰€æœ‰è¾¨è­˜å‡ºçš„æ–‡å­—ï¼ˆæ›è¡Œåˆ†éš”ï¼‰
                "image_path": str,              # æ¨™è¨»åœ–ç‰‡çš„è·¯å¾‘
                "bounding_boxes": list[dict]    # æ¯å€‹æ–‡å­—å€åŸŸçš„åº§æ¨™ã€æ–‡å­—å’Œä¿¡å¿ƒåˆ†æ•¸
                                                # æ ¼å¼: [{"box": [[x1,y1], [x2,y2], [x3,y3], [x4,y4]],
                                                #         "text": str, "score": float}, ...]
            }
        """
        try:
            # è™•ç†è¼¸å…¥æ ¼å¼ä¸¦å–å¾—åœ–ç‰‡è·¯å¾‘
            img_path = self._process_image_input(image_input)

            # è¼‰å…¥åŸå§‹åœ–ç‰‡
            original_image = Image.open(img_path)

            # è¨­ç½®è¼¸å‡ºç›®éŒ„ (åŠ å…¥ timestamp)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
            ocr_output_dir = os.path.join(self.tmp_dir, f"images/{timestamp}")
            os.makedirs(ocr_output_dir, exist_ok=True)

            # Step 1: ä½¿ç”¨ self.layout é€²è¡Œç‰ˆé¢æª¢æ¸¬ï¼Œç²å–é‚Šç•Œæ¡†
            result = self.layout.predict(input=img_path)

            for res in result:
                res.print()
                res.save_to_json(save_path=ocr_output_dir)
                res.save_to_img(save_path=ocr_output_dir)

            # æå–æ–‡å­—å…§å®¹
            json_files = glob.glob(os.path.join(ocr_output_dir, "*.json"))
            if not json_files:
                raise FileNotFoundError(f"No JSON files found in {ocr_output_dir}")

            with open(json_files[0], 'r', encoding='utf-8') as f:
                json_result = json.load(f)

            # æå– bounding boxes
            layout_boxes = []
            if "dt_polys" in json_result:
                for box in json_result["dt_polys"]:
                    layout_boxes.append(box)

            if not layout_boxes:
                # å¦‚æœæ²’æœ‰æª¢æ¸¬åˆ°ç‰ˆé¢ï¼Œè¿”å›ç©ºçµæœ
                return {
                    "text": "",
                    "image_path": "",
                    "bounding_boxes": []
                }

            # Step 2: æ ¹æ“šé‚Šç•Œæ¡†è£åˆ‡åœ–ç‰‡ä¸¦é€²è¡Œ OCR
            all_bounding_boxes = []
            all_texts = []

            for idx, layout_box in enumerate(layout_boxes):
                # è£åˆ‡åœ–ç‰‡ - ä½¿ç”¨é€è¦–è®Šæ›è™•ç†4é»å¤šé‚Šå½¢
                # layout_box æ ¼å¼: [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]

                # è½‰æ›ç‚º numpy array
                src_points = np.array(layout_box, dtype=np.float32)

                # è¨ˆç®—ç›®æ¨™çŸ©å½¢çš„å¯¬åº¦å’Œé«˜åº¦
                width = int(max(
                    np.linalg.norm(src_points[0] - src_points[1]),
                    np.linalg.norm(src_points[2] - src_points[3])
                ))
                height = int(max(
                    np.linalg.norm(src_points[0] - src_points[3]),
                    np.linalg.norm(src_points[1] - src_points[2])
                ))

                # å®šç¾©ç›®æ¨™çŸ©å½¢çš„å››å€‹è§’é»
                dst_points = np.array([
                    [0, 0],
                    [width - 1, 0],
                    [width - 1, height - 1],
                    [0, height - 1]
                ], dtype=np.float32)

                # è¨ˆç®—é€è¦–è®Šæ›çŸ©é™£
                matrix = cv2.getPerspectiveTransform(src_points, dst_points)

                # å°‡ PIL Image è½‰æ›ç‚º numpy array
                img_array = np.array(original_image)

                # åŸ·è¡Œé€è¦–è®Šæ›
                cropped_array = cv2.warpPerspective(img_array, matrix, (width, height))

                # è½‰æ›å› PIL Image
                cropped_image = Image.fromarray(cropped_array)

                # å„²å­˜è£åˆ‡å¾Œçš„åœ–ç‰‡
                crop_path = os.path.join(self.tmp_dir, f"crop_{idx}_{layout_box}.jpg")
                cropped_image.save(crop_path)

                # Step 3: å°è£åˆ‡å¾Œçš„åœ–ç‰‡é€²è¡Œ OCR
                # PaddleOCRVLManga.predict() è¿”å›å­—ä¸²ï¼Œä¸è¿”å›é‚Šç•Œæ¡†
                ocr_text = self.ocr.predict(crop_path)

                # å°‡çµæœèˆ‡ç‰ˆé¢æ¡†é—œè¯
                if ocr_text and ocr_text.strip():
                    bbox_info = {
                        "box": layout_box,  # ä½¿ç”¨ç‰ˆé¢æª¢æ¸¬çš„é‚Šç•Œæ¡†
                        "text": ocr_text.strip(),
                        "score": None  # PaddleOCRVLManga ä¸æä¾›ä¿¡å¿ƒåˆ†æ•¸
                    }
                    all_bounding_boxes.append(bbox_info)
                    all_texts.append(ocr_text.strip())

            response = {
                "text": "\n".join(all_texts),
                "image_path": image_input,
                "bounding_boxes": all_bounding_boxes
            }

            return response

        finally:
            # æ¯æ¬¡æ¨ç†å¾Œæ¸…ç† GPU è¨˜æ†¶é«”
            self._clear_gpu_memory()
            # æ¸…ç†èˆŠçš„è¼¸å‡ºç›®éŒ„
            self._cleanup_old_outputs()


def main():
    parser = argparse.ArgumentParser(description='PaddleOCR-VL åœ–ç‰‡æ–‡å­—è¾¨è­˜')
    parser.add_argument('--image', type=str, help='å–®å¼µåœ–ç‰‡è·¯å¾‘')
    parser.add_argument('--input-dir', type=str, help='åœ–ç‰‡ç›®éŒ„è·¯å¾‘ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰')
    parser.add_argument('--no-recursive', action='store_true', help='ä¸éè¿´æœå°‹å­ç›®éŒ„ï¼ˆåƒ…ç”¨æ–¼ --input-dirï¼‰')
    parser.add_argument('--model-dir', type=str,
                        default='/tmp2/share_data/models--PaddlePaddle--PaddleOCR-VL/',
                        help='æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--text-det-model-dir', type=str,
                        default=None,
                        help='æ–‡å­—åµæ¸¬æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--text-rec-model-dir', type=str,
                        default=None,
                        help='æ–‡å­—è¾¨è­˜æ¨¡å‹è·¯å¾‘ (é è¨­: PaddleOCR/output/inference/PP-OCRv5_comic_rec_infer_epoch200)')
    parser.add_argument('--output', type=str, help='è¼¸å‡ºæ–‡å­—æª”æ¡ˆè·¯å¾‘ï¼ˆå–®å¼µåœ–ç‰‡ï¼‰æˆ–åˆä½µæ–‡å­—æª”æ¡ˆè·¯å¾‘ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰')
    parser.add_argument('--output-dir', type=str, help='è¼¸å‡ºç›®éŒ„è·¯å¾‘ï¼ˆæ‰¹æ¬¡è™•ç†æ™‚æ¯å¼µåœ–ç‰‡åˆ†åˆ¥å„²å­˜ï¼‰')
    parser.add_argument('--save-image', type=str, help='å„²å­˜æ¨™è¨»åœ–ç‰‡è·¯å¾‘ï¼ˆé¸å¡«ï¼‰')

    args = parser.parse_args()

    # æª¢æŸ¥å¿…é ˆæä¾› --image æˆ– --input-dir å…¶ä¸­ä¹‹ä¸€
    if not args.image and not args.input_dir:
        print(f"âŒ éŒ¯èª¤ï¼šè«‹æä¾› --image æˆ– --input-dir åƒæ•¸", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    if args.image and args.input_dir:
        print(f"âŒ éŒ¯èª¤ï¼š--image å’Œ --input-dir ä¸èƒ½åŒæ™‚ä½¿ç”¨", file=sys.stderr)
        sys.exit(1)

    print(f"ğŸ”§ è¼‰å…¥ OCR æ¨¡å‹...")
    ocr = OCR(
        text_det_model_dir=args.text_det_model_dir,
        text_recognition_model_dir=args.text_rec_model_dir,
        output_dir=args.output_dir
    )

    # å–®å¼µåœ–ç‰‡è™•ç†
    if args.image:
        if not os.path.exists(args.image):
            print(f"âŒ éŒ¯èª¤ï¼šåœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨ - {args.image}", file=sys.stderr)
            sys.exit(1)

        print(f"ğŸ–¼ï¸  è™•ç†åœ–ç‰‡ï¼š{args.image}")
        result = ocr.predict(args.image)

        # è¼¸å‡ºè¾¨è­˜æ–‡å­—
        print("\nğŸ“ å®Œæ•´ JSON çµæœï¼š")
        print("=" * 60)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        print("=" * 60)

        # å„²å­˜è¼¸å‡ºï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(result['text'])
            print(f"\nğŸ’¾ æ–‡å­—å·²å„²å­˜è‡³ï¼š{args.output}")


    # ç›®éŒ„æ‰¹æ¬¡è™•ç†
    elif args.input_dir:
        if not os.path.exists(args.input_dir):
            print(f"âŒ éŒ¯èª¤ï¼šç›®éŒ„ä¸å­˜åœ¨ - {args.input_dir}", file=sys.stderr)
            sys.exit(1)

        print(f"ğŸ“ è¼‰å…¥ç›®éŒ„ï¼š{args.input_dir}")
        recursive = not args.no_recursive
        if not recursive:
            print(f"   æ¨¡å¼ï¼šåƒ…æœå°‹ç•¶å‰ç›®éŒ„ï¼ˆä¸éè¿´ï¼‰")
        else:
            print(f"   æ¨¡å¼ï¼šéè¿´æœå°‹æ‰€æœ‰å­ç›®éŒ„")
        image_paths = ocr.load_directory(args.input_dir, recursive=recursive)

        if not image_paths:
            print(f"âš ï¸  è­¦å‘Šï¼šç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡æª”æ¡ˆ", file=sys.stderr)
            sys.exit(0)

        print(f"âœ… æ‰¾åˆ° {len(image_paths)} å¼µåœ–ç‰‡\n")

        # æ‰¹æ¬¡è™•ç†
        results = ocr.predict_batch(image_paths)

        # è¼¸å‡ºçµæœæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹æ¬¡è™•ç†çµæœæ‘˜è¦ï¼š")
        print("=" * 60)

        success_count = sum(1 for r in results if 'error' not in r)
        error_count = len(results) - success_count

        print(f"âœ… æˆåŠŸï¼š{success_count} å¼µ")
        print(f"âŒ å¤±æ•—ï¼š{error_count} å¼µ")

        # å„²å­˜çµæœç‚º JSON æª”
        if args.output_dir:
            os.makedirs(args.output_dir, exist_ok=True)
            results_json_path = os.path.join(args.output_dir, "ocr.json")
            with open(results_json_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ æ‰¹æ¬¡çµæœå·²å„²å­˜è‡³ï¼š{results_json_path}")


if __name__ == "__main__":
    main()
